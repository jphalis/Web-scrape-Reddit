from __future__ import unicode_literalsimport datetimeimport difflibimport jsonimport reimport requestsimport timefrom openpyxl import *from openpyxl.styles import Font, PatternFillfrom openpyxl.styles.borders import Border, Sidefrom exclude import excluding_wordsfrom focus_words import key_wordsNEW_ITEMS = 0def highlight_cell(ws, col, row):    """    Highlights the cell in an Excel file.    """    ws.cell(column=col, row=row).fill = PatternFill(        start_color='ffff00',        end_color='ffff00',        fill_type='solid')    return wsdef get_json(url, search_data, headers=None):    """    Returns data in json format.    """    time.sleep(3)    response = requests.get(        url=url,        data=json.dumps(search_data),        headers=headers,        verify=False)    response.text    return response.json()class RedditPostsScraper(object):    def __init__(self):        # URLs to be scraped        self.search_links = [            "http://www.reddit.com/r/Malware/",            "http://www.reddit.com/r/Malware/new/"        ]        # Fields returned in json        self.search_request = {            "kind": "Listing",            "data": {                "modhash": "",                "children": [{                    "kind": None,                    "data": {                        "domain": None,                        "banned_by": None,                        "media_embed": {},                        "subreddit": None,                        "selftext_html": None,                        "selftext": None,                        "likes": None,                        "suggested_sort": None,                        "user_reports": [],                        "secure_media": None,                        "link_flair_text": None,                        "id": None,                        "from_kind": None,                        "glided": None,                        "archived": None,                        "clicked": None,                        "report_reasons": None,                        "author": None,                        "media": None,                        "score": None,                        "approved_by": None,                        "over_18": None,                        "hidden": None,                        "num_comments": None,                        "thumbnail": None,                        "subreddit_id": None,                        "hide_score": None,                        "edited": None,                        "link_flair_css_class": None,                        "author_flair_css_class": None,                        "downs": None,                        "secure_media_embed": {},                        "saved": None,                        "removal_reason": None,                        "stickied": None,                        "from": None,                        "is_self": None,                        "from_id": None,                        "permalink": None,                        "locked": None,                        "name": None,                        "created": None,                        "url": None,                        "author_flair_text": None,                        "quarantine": None,                        "title": None,                        "created_utc": None,                        "distinguished": None,                        "mod_reports": [],                        "visited": None,                        "num_reports": None,                        "ups": None                    }                }],                "after": None,                "before": None            }        }    def add_to_excel(self, titles, links, created):        """        Adds the collected titles and links to an Excel document.        """        # Main doucment information        ws1 = wb.active        ws1.title = "Reddit Data"        # Header cells        ws1['A1'] = "Titles"        ws1['B1'] = "URL"        ws1['C1'] = "Created"        header_cells = [            ws1['A1'],            ws1['B1'],            ws1['C1']        ]        for cell in header_cells:            cell.font = Font(                bold=True,                name='Arial',                color='FF0000FF')            cell.border = Border(                bottom=Side(style='medium', color='add8e6'))        # Data cells        i = j = k = 0        for row in range(2, len(titles) + 2):            # Titles            for col in range(1, 2):                if ws1.cell(column=col, row=row).value == titles[i]:                    highlight_cell(ws=ws1, col=col, row=row)                else:                    global NEW_ITEMS                    NEW_ITEMS += 1                    ws1.cell(                        column=col,                        row=row,                        value="{}".format(titles[i]))                i += 1            # URLs            for col in range(2, 3):                if ws1.cell(column=col, row=row).value == links[j]:                    highlight_cell(ws=ws1, col=col, row=row)                              else:                    ws1.cell(                        column=col,                        row=row,                        value="{}".format(links[j]))                j += 1            # Creation date            for col in range(3, 4):                if ws1.cell(column=col, row=row).value == created[k]:                    highlight_cell(ws=ws1, col=col, row=row)                              else:                    formatted_date = datetime.datetime.fromtimestamp(                        int(created[k])).strftime("%m-%d-%Y %H:%M:%S")                    ws1.cell(                        column=col,                        row=row,                        value="{}".format(formatted_date))                k += 1        # Save Excel file        wb.save('Scraped_Data.xlsx')        return wb    def scrape_posts(self, max_count=100):        """        Scrapes the URLs in the search_links list,        collects the titles, links, and creation date        from each URL, checks to see if the titles match        any key words from focus_words.py and prepares        the relevant information to be imported into Excel.        """        after = ""        titles = []        links = []        created = []        final_titles = []        final_links = []        final_created = []        for link in self.search_links:            print "Gathering data from {}...".format(link)            count = 0            while count < max_count:                # Prepare URL information to fetch from                params = ".json?count={0}&after={1}".format(count, after)                data = get_json(                    url=link + params,                    search_data=self.search_request,                    headers={"User-agent":"web:com.bd.bdbot:v1.2.4 (by /u/e4cjOC6yb98Y_g)"})                count += 25  # Next page                # Obtain information from Reddit                after = data['data']['after']                for child in data['data']['children']:                    # time.sleep(2)                    titles.append(u"{}".format(child['data']['title']))                    links.append(child['data']['url'])                    created.append(child['data']['created_utc'])                # Check for keywords                i = 0                for item in titles:                    pattern = re.compile(r'\W+')                    for word in map(                            lambda x:                             x.lower().strip('#'),                            pattern.split(item)):                        # Verify word is not in the excluding_words list                        if word not in map(lambda x: x.lower(), excluding_words):                            matches = difflib.get_close_matches(                                word,                                map(lambda x: x.lower(), key_words),                                cutoff=0.9)                            # Verify the title and link are not already added                            # and are relevant to the key words list                            if len(matches) > 0 and item not in final_titles:                                final_titles.append(item)                                final_links.append(links[i])                                final_created.append(created[i])                    i += 1        print "Creating Excel file..."        # Add data to Excel        self.add_to_excel(            titles=final_titles,            links=final_links,            created=final_created        )        return titlesif __name__ == '__main__':    try:        wb = load_workbook('Scraped_Data.xlsx')    except:        wb = Workbook()    print "Started."    RedditPostsScraper().scrape_posts()    print "Done."    print "- - - - - - -"    if NEW_ITEMS == 1:        print "There is {0} new article.".format(NEW_ITEMS)    else:        print "There are {0} new articles.".format(NEW_ITEMS)    print "- - - - - - -"